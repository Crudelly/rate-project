{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.preprocessing.text as kpt\n",
    "\n",
    "max_words = 1000\n",
    "num_classes = 20\n",
    "\n",
    "tokenizer = kpt.Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(newsgroups_train[\"data\"])  \n",
    "\n",
    "x_train = tokenizer.texts_to_matrix(newsgroups_train[\"data\"], mode='binary') \n",
    "x_test = tokenizer.texts_to_matrix(newsgroups_test[\"data\"], mode='binary') \n",
    "\n",
    "y_train = keras.utils.to_categorical(newsgroups_train[\"target\"], num_classes) \n",
    "y_test = keras.utils.to_categorical(newsgroups_test[\"target\"], num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "          Dense(512, input_shape=(max_words,)),\n",
    "          Activation('relu'),\n",
    "          Dropout(0.5),\n",
    "          Dense(num_classes),\n",
    "          Activation('softmax')\n",
    "        ])\n",
    "\n",
    "# print(model.to_yaml())\n",
    "# print(model.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/50\n",
      "10182/10182 [==============================] - 4s 352us/step - loss: 2.0663 - acc: 0.4113 - val_loss: 1.1826 - val_acc: 0.7102\n",
      "Epoch 2/50\n",
      "10182/10182 [==============================] - 3s 282us/step - loss: 0.9954 - acc: 0.7229 - val_loss: 0.8648 - val_acc: 0.7641\n",
      "Epoch 3/50\n",
      "10182/10182 [==============================] - 3s 294us/step - loss: 0.7120 - acc: 0.7984 - val_loss: 0.7733 - val_acc: 0.7792\n",
      "Epoch 4/50\n",
      "10182/10182 [==============================] - 3s 292us/step - loss: 0.5524 - acc: 0.8444 - val_loss: 0.7058 - val_acc: 0.7915\n",
      "Epoch 5/50\n",
      "10182/10182 [==============================] - 3s 311us/step - loss: 0.4481 - acc: 0.8747 - val_loss: 0.6969 - val_acc: 0.7898\n",
      "Epoch 6/50\n",
      "10182/10182 [==============================] - 3s 288us/step - loss: 0.3654 - acc: 0.8992 - val_loss: 0.6749 - val_acc: 0.7924\n",
      "Epoch 7/50\n",
      "10182/10182 [==============================] - 3s 309us/step - loss: 0.3078 - acc: 0.9174 - val_loss: 0.6849 - val_acc: 0.7898\n",
      "Epoch 8/50\n",
      "10182/10182 [==============================] - 3s 305us/step - loss: 0.2588 - acc: 0.9364 - val_loss: 0.6693 - val_acc: 0.8004\n",
      "Epoch 9/50\n",
      "10182/10182 [==============================] - 3s 305us/step - loss: 0.2145 - acc: 0.9510 - val_loss: 0.6971 - val_acc: 0.7906\n",
      "Epoch 10/50\n",
      "10182/10182 [==============================] - 3s 297us/step - loss: 0.1849 - acc: 0.9564 - val_loss: 0.7027 - val_acc: 0.7942\n",
      "Epoch 11/50\n",
      "10182/10182 [==============================] - 3s 305us/step - loss: 0.1598 - acc: 0.9656 - val_loss: 0.7017 - val_acc: 0.7906\n",
      "Epoch 12/50\n",
      "10182/10182 [==============================] - 3s 295us/step - loss: 0.1405 - acc: 0.9703 - val_loss: 0.7252 - val_acc: 0.7924\n",
      "Epoch 13/50\n",
      "10182/10182 [==============================] - 3s 321us/step - loss: 0.1144 - acc: 0.9777 - val_loss: 0.7308 - val_acc: 0.7942\n",
      "Epoch 14/50\n",
      "10182/10182 [==============================] - 3s 294us/step - loss: 0.1016 - acc: 0.9799 - val_loss: 0.7458 - val_acc: 0.7915\n",
      "Epoch 15/50\n",
      "10182/10182 [==============================] - 3s 306us/step - loss: 0.0884 - acc: 0.9836 - val_loss: 0.7712 - val_acc: 0.7915\n",
      "Epoch 16/50\n",
      "10182/10182 [==============================] - 3s 294us/step - loss: 0.0760 - acc: 0.9864 - val_loss: 0.7821 - val_acc: 0.7871\n",
      "Epoch 17/50\n",
      "10182/10182 [==============================] - 3s 309us/step - loss: 0.0736 - acc: 0.9866 - val_loss: 0.7860 - val_acc: 0.7898\n",
      "Epoch 18/50\n",
      "10182/10182 [==============================] - 3s 311us/step - loss: 0.0598 - acc: 0.9907 - val_loss: 0.8051 - val_acc: 0.7915\n",
      "Epoch 19/50\n",
      "10182/10182 [==============================] - 3s 312us/step - loss: 0.0540 - acc: 0.9923 - val_loss: 0.8150 - val_acc: 0.7880\n",
      "Epoch 20/50\n",
      "10182/10182 [==============================] - 3s 294us/step - loss: 0.0490 - acc: 0.9945 - val_loss: 0.8341 - val_acc: 0.7827\n",
      "Epoch 21/50\n",
      "10182/10182 [==============================] - 3s 318us/step - loss: 0.0457 - acc: 0.9926 - val_loss: 0.8508 - val_acc: 0.7889\n",
      "Epoch 22/50\n",
      "10182/10182 [==============================] - 3s 296us/step - loss: 0.0404 - acc: 0.9954 - val_loss: 0.8589 - val_acc: 0.7871\n",
      "Epoch 23/50\n",
      "10182/10182 [==============================] - 3s 312us/step - loss: 0.0362 - acc: 0.9955 - val_loss: 0.8562 - val_acc: 0.7959\n",
      "Epoch 24/50\n",
      "10182/10182 [==============================] - 3s 295us/step - loss: 0.0351 - acc: 0.9954 - val_loss: 0.8669 - val_acc: 0.7933\n",
      "Epoch 25/50\n",
      "10182/10182 [==============================] - 3s 309us/step - loss: 0.0341 - acc: 0.9954 - val_loss: 0.8830 - val_acc: 0.7924\n",
      "Epoch 26/50\n",
      "10182/10182 [==============================] - 3s 297us/step - loss: 0.0338 - acc: 0.9958 - val_loss: 0.8809 - val_acc: 0.7906\n",
      "Epoch 27/50\n",
      "10182/10182 [==============================] - 3s 311us/step - loss: 0.0325 - acc: 0.9954 - val_loss: 0.9090 - val_acc: 0.7827\n",
      "Epoch 28/50\n",
      "10182/10182 [==============================] - 3s 293us/step - loss: 0.0287 - acc: 0.9962 - val_loss: 0.8971 - val_acc: 0.7906\n",
      "Epoch 29/50\n",
      "10182/10182 [==============================] - 3s 313us/step - loss: 0.0224 - acc: 0.9973 - val_loss: 0.9310 - val_acc: 0.7915\n",
      "Epoch 30/50\n",
      "10182/10182 [==============================] - 3s 295us/step - loss: 0.0256 - acc: 0.9960 - val_loss: 0.9327 - val_acc: 0.7889\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping  \n",
    "\n",
    "early_stopping=EarlyStopping(monitor='loss')  \n",
    "batch_size = 100\n",
    "epochs = 50\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7532/7532 [==============================] - 1s 72us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7281236063592054, 0.651752520924354]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
